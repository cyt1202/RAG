# RAG
新手尝试搭建一个基于文档的问答模型！模型结构如下：

1.文档分词 2. 向量化 3. 存入向量数据库 4. 在向量数据库中检索对应知识 5. 返回给大语言模型的API

## 文档分词
分词应该尽量准确的进行语义分割

我最开始进行了简单粗暴的尝试：基于分隔符的递归切分

根据用  `\n\n `切分整个文档;如果切出来的chunks大于chunk_size,那么只针对过大的chunk进行下一个优先级的分隔符 `\n `切分; 如果用 \n 切分后，某个子块还是太大，就会再对那个子块用空格` " " `切分。如果最后还不行，就会强制按字符 `"" `切分，以确保没有任何一个块会超过 chunk_size
