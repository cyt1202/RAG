# 基于Qwen大模型的混合检索RAG系统

[](https://www.python.org/)
[](https://www.langchain.com/)
[](https://github.com/facebookresearch/faiss)

本项目是一个先进的检索增强生成（RAG）系统，旨在通过结合\*\*知识图谱（Knowledge Graph）**与**向量检索（Vector Retrieval）\*\*两种模式，为用户提供更精准、更深入、更具逻辑性的问答体验。

与传统的仅依赖语义相似度的RAG不同，本系统首先利用Qwen大模型从源文档中提取结构化的知识图谱，同时对文档进行深度语义切分和向量化。在回答问题时，系统会并行地从知识图谱中检索精确的事实，并从向量数据库中召回相关的上下文段落，最终将两种信息融合，生成全面且可靠的答案。

### 核心技术栈

  * **大语言模型 (LLM)**: 阿里云通义千问 (`qwen-plus`, `Qwen/Qwen3-Embedding-0.6B`)
  * **文本切分**: `chonky` 语义分割器
  * **向量化**: `SentenceTransformerEmbeddings` 结合 Qwen 嵌入模型
  * **向量数据库**: `FAISS`
  * **框架**: `LangChain`
  * **知识图谱**: 使用 `LLMGraphTransformer` 自动构建

-----

## 📁 项目结构

```
.
├── input/                  # 存放待处理的源文档 (.pdf, .docx)
├── output/                 # 存放语义分割后的文本片段和知识图谱JSON文件
├── vector_db/              # 存放生成的FAISS向量数据库
├── rag_output/             # 存放RAG问答系统最终输出的答案文件
├── other_splitting_models/ # 其他文本分割模型的尝试与实现
├── other_RAG_methods/      # 其他RAG方法的尝试（如多级索引）
├── 1_build_kg.py           # 脚本：读取文档，调用Qwen API生成知识图谱
├── 2_build_vectorstore.py  # 脚本：文档切分、向量化并构建FAISS向量数据库
├── 3_hybrid_rag_cli.py     # 核心脚本：执行混合检索问答的命令行工具
├── .env                    # 环境变量文件，用于存放API Key
└── README.md               # 本文档
```

⚠️ **重要提示**：关于 `vector_db` 文件夹

> 如果你更改了 `input` 文件夹中的源文件，你需要手动删除 `vector_db` 中对应的旧向量库文件夹（例如 `"vector_db/faiss_pdf_chonky_index"`）。本项目的脚本设计为如果检测到向量库已存在，则会跳过重建过程。因此，为确保对新文档进行提问，请务必删除旧的向量库。

-----

## ⚙️ 环境配置

请按照以下步骤配置您的运行环境。

### 1\. 创建并激活虚拟环境 (推荐)

```bash
# 使用 conda
conda create -n qwen_rag python=3.12.9
conda activate qwen_rag

# 或者使用 venv
python -m venv qwen_rag_env
source qwen_rag_env/bin/activate  # on Windows: qwen_rag_env\Scripts\activate
```

### 2\. 安装依赖库

本项目的所有依赖都已整理。你可以创建一个 `requirements.txt` 文件，内容如下：

**`requirements.txt`**:

```
langchain
langchain-community
langchain-experimental
langchain-openai
chonky
pypdf
docx2txt
faiss-cpu
sentence-transformers
python-dotenv
tiktoken
```

然后通过一行命令安装所有依赖：

```bash
pip install -r requirements.txt
```

> **注意**: 如果你的机器有支持CUDA的NVIDIA GPU，可以将 `faiss-cpu` 替换为 `faiss-gpu` 以获得更快的速度。

### 3\. 配置API Key

本项目需要调用阿里云百炼的Qwen模型API。

1.  **创建 `.env` 文件**: 在项目的根目录下创建一个名为 `.env` 的文件。
2.  **填入API Key**: 在 `.env` 文件中添加以下内容，将 `sk-xxx` 替换为你自己的API Key。
    ```
    DASHSCOPE_API_KEY="sk-xxxxxxxxxxxxxxxxxxxxxxxx"
    ```
    脚本会自动加载此文件中的环境变量。

或者，你也可以在终端中临时设置环境变量（关闭终端后失效）：

  * **Windows (PowerShell):**
    ```powershell
    $env:DASHSCOPE_API_KEY = "sk-xxxxxxxxxxxxxxxxxxxxxxxx"
    ```
  * **macOS / Linux:**
    ```bash
    export DASHSCOPE_API_KEY="sk-xxxxxxxxxxxxxxxxxxxxxxxx"
    ```

-----

## 🚀 运行指南

请按照以下顺序执行脚本，完成整个RAG流程。

### 第1步: 放置源文件

将你希望系统学习的 `.pdf` 或 `.docx` 文件放入 `input` 文件夹。例如，放入 `input/MyReport.pdf`。

### 第2步: 构建知识图谱

运行 `1_build_kg.py` 脚本，它会读取 `input` 文件夹中的文档，并生成一个知识图谱。

```bash
python 1_build_kg.py
```

  * **输入**: `input/KG_test.pdf` (默认，可在代码中修改)
  * **输出**: `output/test_KG.json`

### 第3步: 创建向量数据库

运行 `2_build_vectorstore.py` 脚本，它会对文档进行切分、向量化，并构建FAISS索引。

```bash
python 2_build_vectorstore.py
```

  * **输入**: `input/KG_test.pdf` (默认，可在代码中修改)
  * **输出**: `vector_db/faiss_pdf_chonky_index` 文件夹

### 第4步: 执行混合检索问答

这是最后一步。运行核心脚本 `3_hybrid_rag_cli.py`，并提出你的问题。

**查看帮助信息:**

```bash
python 3_hybrid_rag_cli.py -h
```

**示例用法:**

  * **使用默认路径进行提问：**

    ```bash
    python 3_hybrid_rag_cli.py "What is the method of MastSAM?"
    ```

    这会使用默认的知识图谱和向量库，并将答案打印到终端，同时保存在 `rag_output/rag_answer.txt`。

  * **指定自定义路径进行提问：**

    ```bash
    python 3_hybrid_rag_cli.py "How does Chronomirror work?" --kg-path "my_kg.json" --db-path "my_faiss_db" --output-file "my_answer.txt"
    ```

    这个命令会从你指定的路径加载数据，并将结果保存在 `my_answer.txt`。

-----

## 🔬 其他尝试与扩展

  * **`other_splitting_models`**:
    这个文件夹包含了我对其他文本分割方法的探索。`chonky` 在语义完整性方面表现出色，因此被选为主要方法。如果你希望尝试不同的切分策略，可以参考此文件夹中的代码。

  * **`other_RAG_methods`**:
    这里记录了我对多级索引（Hierarchical Indices）等其他RAG架构的尝试。虽然最终选择了混合检索模式，但这些探索对于理解不同RAG方法的优劣非常有帮助。

  * **扩展性**:
    本项目是高度可扩展的。例如，在 `3_hybrid_rag_cli.py` 中，你可以轻易地将 `search_in_kg` 函数的简单关键词匹配逻辑，替换为更复杂的图数据库查询（如Neo4j + Cypher），以实现更强大的多跳推理能力。


好的，完全没问题。将设计思路和技术选型背后的原理清晰地表达出来，是优秀技术文档的关键。我会结合你的思考和你提供的细节，用更专业、更精炼的语言重构这部分内容，并融入我的理解，形成一个完整的“原理与设计”章节。

你可以将以下内容添加到你的 `README.md` 文件中，它可以作为一个独立的大章节。

---

## 核心原理与设计哲学

本项目的核心是构建一个能够深度理解复杂文档并提供精准回答的RAG系统。为了实现这一目标，我们没有采用单一的检索策略，而是设计了一套结合了先进语义分割和知识图谱的**混合检索（Hybrid Retrieval）**架构。

### 挑战：复杂文档的深度理解

本项目特意选用结构复杂的学术论文作为处理对象，以此来挑战和解决标准RAG流程中的常见瓶颈：

1.  **切割难题**：与格式清晰的文档不同，论文包含大段连续的文本、复杂的逻辑层次和隐晦的上下文关联，简单的按符号或固定长度切分，极易破坏语义完整性。
2.  **检索困境**：切割出的文本块（chunks）缺乏明确的标题或索引。当用户提问（例如“这个模型的方法是什么？”）时，单纯依赖向量相似度检索，往往会面临“语义稀释”问题——包含核心细节的段落可能因为关键词密度低而被忽略，反而召回了高频提及关键词的引言或结论部分，导致答案偏离重点。

为了应对这些挑战，我们对流程中的两个关键环节——**文档切割**和**信息检索**——进行了深度优化。

### 1. 语义分割策略的演进

我们对三种不同层次的文本分割方法进行了评估，旨在找到保留语义最完整、最适合下游检索的方案。

* **基线方法：递归字符分割 (Recursive Character Splitting)**
    * **原理**：一种简单粗暴的、自顶向下的规则切分。它首先尝试用段落分隔符（`\n\n`）分割，如果子块超长，则降级使用句子分隔符（`\n`），再降级到空格，最终强制按字符切分，确保所有文本块都不超过预设长度。
    * **结论**：虽然能保证长度合规，但频繁的硬性切分严重破坏了句子的语义连贯性，作为基线参照。

* **启发式方法：`semantic-text-splitter`**
    * **原理**：一种基于文本结构层级的、性能优先的启发式分割器。它定义了 `段落 > 句子 > 单词` 的语义层级，采用“自顶向下”策略寻找最高级别的语义单元，再通过“贪心合并”算法在不超过长度限制的前提下，将相邻的同级单元（如多个句子）聚合在一起，形成一个chunk。
    * **结论**：在性能和效果间取得了很好的平衡，显著优于递归分割。它不依赖大型AI模型，速度快，但在处理无明显段落结构的复杂文本时，效果仍有局限。

* **模型驱动方法：`chonky` (本项目最终选用)**
    * **原理**：一个基于Transformer的、为语义分割专门训练的AI模型。它将文本分割视为一个**Token分类任务**，通过学习大量数据，精准地在Token序列中预测出最佳的“语义断点”（`separator`）。
    * **结论**：在我们的测试中，`chonky` 的分割结果在语义完整性上表现最佳。它能更好地理解句子和段落间的内在联系，生成高质量的文本块，为后续的向量检索奠定了坚实的基础。

### 2. 混合检索：为何引入知识图谱？

尽管 `chonky` 提供了高质量的文本块，但“语义稀释”的问题依然存在。向量检索本质上是**局部语义**的匹配，它擅长找到“描述相似”的片段，却难以把握整个文档的**全局结构**和**实体间的精确关系**。

这就是引入知识图谱的核心原因。

> **AI的理解：** 知识图谱与向量数据库并非竞争关系，而是**完美的互补关系**。向量数据库是“博闻强识的阅读者”，能快速找到相关段落；而知识图谱则是“逻辑清晰的思考者”，能提供整个知识体系的结构化骨架。

在这个项目中，它们的角色分工如下：

* **知识图谱 (全局事实骨架)**:
    * **功能**: 负责捕捉文档中**确定性的、结构化的事实**，如 `(模型A) -[基于]-> (技术B)`，`(作者C) -[提出]-> (方法D)`。它构建了一个全局的、宏观的实体关系网络。
    * **应用**: 当用户提出**高层次、抽象或关系型**的问题时（例如，“模型A和模型B有什么关联？”或“这个方法的核心贡献是什么？”），知识图谱能提供精准、无歧义的事实依据，直接回答问题的核心。

* **向量检索 (局部上下文补充)**:
    * **功能**: 负责召回与用户问题在**语义上最相关**的原始文本段落。
    * **应用**: 当用户提出需要**详细描述、具体解释或背景信息**的问题时（例如，“请详细解释模型A的具体实现步骤”），向量检索能提供丰富的、非结构化的上下文信息。

通过**混合检索**，我们的RAG系统在响应用户查询时，会并行地：
1.  **查询知识图谱**，获取关于核心实体的**精确事实**。
2.  **查询向量数据库**，召回围绕问题本身的**详细上下文**。

最终，这两部分信息被融合在一起，共同呈现给LLM。这使得最终生成的答案既有知识图谱带来的**事实准确性**和**逻辑结构性**，又有向量检索带来的**丰富细节**和**上下文深度**，从而实现了远超单一检索模式的问答效果。